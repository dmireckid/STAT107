{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4519f2a93512ff0d6bab816a9d68bb01",
     "grade": false,
     "grade_id": "cell-27777987dede72aa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# EC Notebook for Lecture 13: Algorithms\n",
    "\n",
    "This extra credit Python notebook will let you practice the material you saw in lecture.  Completing all parts of this notebook will earn +1 extra credit point to your grade in STAT 107! :)\n",
    "\n",
    "This notebook is worth +1 if turned in before 11:30 am on **Friday, Sept. 27** *(30 minutes before the next STAT 107 lecture)*.  You can feel free to complete it anytime for extra practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "78609bbb8a54a08adc550fe3c6d86c7e",
     "grade": false,
     "grade_id": "cell-dae7e2d1726d4807",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1. Loading pandas and importing data\n",
    "\n",
    "In this extra credit notebook, we will still exploring the information hidden in the \"Illini Football\" dataset -- as we did in lecture 13 -- to answer some questions.\n",
    "\n",
    "you can access the \"Illini Football\" dataset here: \n",
    "https://raw.githubusercontent.com/wadefagen/datasets/master/illini-football/illini-football-scores.csv\n",
    "\n",
    "Next, you need to load the pandas and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f041ed718460bfa6200121bdf2ebe2d7",
     "grade": false,
     "grade_id": "cell-c08171d36379ef97",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = ...\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d8c0507afd04537f73bd6cb8f2019847",
     "grade": false,
     "grade_id": "cell-54f155e6705553d7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2 Puzzle Questions from Lecture.\n",
    "We have load the csv dataset to the python, and let us answer some intersting questions according to the information which the dataset provides for us. \n",
    "\n",
    "### Question 1:\n",
    "How many unique opponents have we played against? \n",
    "How many times have we played against each opponent?\n",
    "What is the Illini win-loss record against Purdue and Chicago, (that is Win - Lost)? \n",
    "How many homecoming games have we played?\n",
    "What is our Win-Loss record among homecoming games, (that is Win - Lost)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3d9195b588d5a19d8252e6527770d549",
     "grade": false,
     "grade_id": "cell-4e3bbaa087fd76f9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "uniq_opponent = ...\n",
    "times_each = ...\n",
    "wins_lost_purdue = ...\n",
    "wins_lost_chicago = ...\n",
    "num_homecoming = ...\n",
    "wins_lost_homecoming = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "41516dcee984fc76c9e6732911a4eb22",
     "grade": true,
     "grade_id": "cell-07f8399e796c5d46",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## == TEST CASES for Question 1 ==\n",
    "# - This read-only cell contains test cases for your previous cell.\n",
    "# - If this cell runs without any error our output, you PASSED all test cases!\n",
    "# - If this cell results in any errors, check you previous cell, make changes, and RE-RUN your code and then this cell.\n",
    "\n",
    "assert(uniq_opponent  == 131), \"The unique opponent number does not appear correct.\"\n",
    "assert(times_each[0] == 2), \"The times against each opponent does not appear correct.\"\n",
    "assert(wins_lost_chicago == 4), \"The wins - lost against Chicago does not appear correct.\"\n",
    "assert(num_homecoming == 108), \"The number of Homecoming does not appear correct.\"\n",
    "assert(wins_lost_homecoming == -18), \"The wins - lost at Homecoming does not appear correct.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6c6cbc0d8fc693739ff2b24fe98e4d1d",
     "grade": false,
     "grade_id": "cell-0205747f965bc93b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3 Algorithm\n",
    "When we analyze the dataset, we are only curious about some certain columns of the dataset, so it is intuitively to subset the whoel dataset by removing some columns or just select some columns. \n",
    "\n",
    "\n",
    "### Question 2:\n",
    "Try to subset the \"df\" dataset as a new dataset called \"dfnew\" which dose not include \"Season\", \"Date\", \"Note\".\n",
    "Now, I believe you have got the dataset \"dfnew\", let us calculate the mean, median and standard deviation for IlliniScore at home (\"vs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5492beb7cd7e6f3d801b9547d9523f51",
     "grade": false,
     "grade_id": "cell-8a5e50c5c1967623",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "dfnew = ...\n",
    "mean = ...\n",
    "median = ...\n",
    "sd = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b4ffad708c64a651096c4cd66859bfd0",
     "grade": true,
     "grade_id": "cell-92108dd37135594b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## == TEST CASES for Question 2 ==\n",
    "# - This read-only cell contains test cases for your previous cell.\n",
    "# - If this cell runs without any error our output, you PASSED all test cases!\n",
    "# - If this cell results in any errors, check you previous cell, make changes, and RE-RUN your code and then this cell.\n",
    "\n",
    "assert(round(mean,0)  == 21.0), \"The mean of IlliniScore at home does not appear correct.\"\n",
    "assert(median == 20), \"The median of IlliniScore at home does not appear correct.\"\n",
    "assert(round(sd,0) == 16.0), \"The standard deviation of IlliniScore at home does not appear correct.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
